# Automated deployment of ArgoCD Agent to Spoke Clusters via Netbird
# Optimized workflow with Netbird VPN mesh integration for local cluster access
# - Ephemeral Netbird connection for GitHub Actions runner
# - Terraform-managed spoke cluster deployment
# - Agent connectivity verification
# -Remote state management in Google Cloud Storage
name: Deploy ArgoCD Spokes (Netbird)

on:
  # Manual trigger with plan/apply option
  workflow_dispatch:
    inputs:
      terraform_action:
        description: 'Terraform Action'
        required: true
        type: choice
        options:
          - plan
          - apply
        default: 'plan'
      adopt_existing_resources:
        description: 'Import existing ArgoCD agent resources into Terraform state'
        required: false
        type: boolean
        default: false
  # Auto-trigger on push to any branch
  push:
    paths:
      - 'argocd-agent/terraform/**'
      - '.github/workflows/deploy-argocd-spokes-netbird.yaml'

# Required permissions for workflow operations
permissions:
  contents: read           # Read repository content
  id-token: write         # Google Cloud Workload Identity

# Global environment variables used across all jobs
env:
  TERRAFORM_VERSION: '1.9.0'
  KUBECTL_VERSION: '1.28.0'
  WORKING_DIR: 'argocd-agent/terraform/environments/prod'
  CLOUD_PROVIDER: 'gke'
  # Configurable deployment settings (can be overridden via GitHub variables)
  ARGOCD_VERSION: ${{ vars.ARGOCD_VERSION || 'v0.5.3' }}
  HUB_NAMESPACE: ${{ vars.HUB_NAMESPACE || 'argocd' }}
  SPOKE_NAMESPACE: ${{ vars.SPOKE_NAMESPACE || 'argocd' }}

jobs:
  # Job 1: Generate and review Terraform infrastructure plan
  # Includes Netbird connection for spoke cluster access
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    outputs:
      plan_exitcode: ${{ steps.plan.outputs.exitcode }}  # Pass plan result to dependent jobs

    steps:
      # Fetch repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # CRITICAL: Connect runner to Netbird network to access local spoke clusters
      # Netbird cloud version setup
      - name: Install Netbird CLI
        run: |
          curl -fsSL https://pkgs.netbird.io/install.sh | sh

      - name: Connect to Netbird
        run: |
          netbird up --setup-key ${{ secrets.NETBIRD_SETUP_KEY_RUNNERS }} 

      # Wait for Netbird peer sync
      - name: Wait for Netbird peer sync
        run: |
          echo "â³ Waiting for Netbird peer sync..."
          MAX_WAIT=60
          WAITED=0
          
          while [ $WAITED -lt $MAX_WAIT ]; do
            PEERS=$(netbird status | grep "Peers count" | awk '{print $3}')
            echo "Current peers: $PEERS (waited ${WAITED}s)"
            
            # Check if we have connected peers (format: X/Y Connected)
            if echo "$PEERS" | grep -q "/.*Connected" && ! echo "$PEERS" | grep -q "0/0"; then
              echo "âœ… Peers synced!"
              netbird status
              exit 0
            fi
            
            sleep 5
            WAITED=$((WAITED + 5))
          done
          
          echo "âš  Peer sync timeout after ${MAX_WAIT}s, proceeding anyway..."
          netbird status

      # Verify Netbird connectivity
      - name: Verify Netbird connection
        run: |
          echo "ğŸ”Œ Verifying Netbird connection..."

          # Install netbird CLI if available
          if command -v netbird >/dev/null 2>&1; then
            netbird status
          else
            echo "â„¹ Netbird CLI not available in GitHub runner"
            echo "   Connection established via netbird-connect action"
          fi

          # Test connectivity to spoke clusters via Netbird
          echo "Testing spoke cluster connectivity..."
          echo "Reading Netbird IPs from secrets..."

          SPOKE_1_IP="${{ secrets.SPOKE_1_NETBIRD_IP }}"
          SPOKE_2_IP="${{ secrets.SPOKE_2_NETBIRD_IP }}"
          SPOKE_3_IP="${{ secrets.SPOKE_3_NETBIRD_IP }}"

          echo "SPOKE_1_NETBIRD_IP: $SPOKE_1_IP"
          echo "SPOKE_2_NETBIRD_IP: $SPOKE_2_IP"
          echo "SPOKE_3_NETBIRD_IP: $SPOKE_3_IP"

          SPOKE_IPS="$SPOKE_1_IP $SPOKE_2_IP $SPOKE_3_IP"

          for ip in $SPOKE_IPS; do
            if [ ! -z "$ip" ]; then
              echo "Testing connectivity to $ip..."
              if ping -c 3 -W 5 $ip; then
                echo "âœ… Reachable: $ip"
              else
                echo "âš  Cannot reach: $ip (may not be configured)"
              fi
            fi
          done

      # Authenticate to GCP (needed for hub cluster context and state bucket access)
      - name: Setup GCP credentials
        uses: google-github-actions/auth@v3
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Install gcloud CLI
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v3

      # Install kubectl for both hub and spoke cluster access
      - name: Setup kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Configure hub cluster context (needed for PKI operations)
          gcloud container clusters get-credentials ${{ secrets.HUB_CLUSTER_NAME }} \
            --region=${{ secrets.HUB_CLUSTER_LOCATION }} \
            --project=${{ secrets.GCP_PROJECT_ID }}

      # Generate kubeconfig for local spoke clusters using Netbird IPs
      # Spoke clusters are already in Netbird with known stable IPs
      - name: Generate kubeconfig for spoke clusters
        run: |
          echo "ğŸ”§ Generating kubeconfig for local spoke clusters..."
          echo "Spoke clusters are pre-configured in Netbird with known IPs"
          echo ""

          # Read spoke cluster list from secrets
          # Expected format: SPOKE_CLUSTERS=spoke-1,spoke-2,spoke-3
          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"

          if [ -z "$SPOKE_CLUSTERS" ]; then
            echo "âš  SPOKE_CLUSTERS secret not set"
            echo "   Using default: spoke-1"
            SPOKE_CLUSTERS="spoke-1"
          fi

          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"

          for cluster in "${CLUSTERS[@]}"; do
            cluster=$(echo "$cluster" | xargs)  # Trim whitespace

            echo "Processing cluster: '$cluster'"

            # Get Netbird IP and certificates based on cluster name
            case "$cluster" in
              spoke-1|spoke-2)
                NETBIRD_IP="${{ secrets.SPOKE_1_NETBIRD_IP }}"
                CA_CERT="${{ secrets.SPOKE_1_CA_CERT }}"
                CLIENT_CERT="${{ secrets.SPOKE_1_CLIENT_CERT }}"
                CLIENT_KEY="${{ secrets.SPOKE_1_CLIENT_KEY }}"
                ;;
              *)
                echo "  âš  Unknown cluster: $cluster"
                echo "  Expected cluster name: spoke-1 or spoke-2"
                echo "  Please check your SPOKE_CLUSTERS secret"
                continue
                ;;
            esac

            # Use GitHub secrets syntax to get values
            echo "Configuring kubectl for $cluster..."

            if [ ! -z "$NETBIRD_IP" ]; then
              echo "  Netbird IP: $NETBIRD_IP"

              # Create kubeconfig entries
              kubectl config set-cluster $cluster \
                --server=https://$NETBIRD_IP:6443 \
                --certificate-authority=<(echo "$CA_CERT" | base64 -d) \
                --embed-certs=true

              kubectl config set-credentials $cluster-admin \
                --client-certificate=<(echo "$CLIENT_CERT" | base64 -d) \
                --client-key=<(echo "$CLIENT_KEY" | base64 -d) \
                --embed-certs=true

              kubectl config set-context $cluster \
                --cluster=$cluster \
                --user=$cluster-admin

              # Verify connectivity via Netbird
              echo "  Testing cluster API access..."
              if kubectl cluster-info --context $cluster >/dev/null 2>&1; then
                echo "  âœ… Cluster API accessible: $cluster"
              else
                echo "  âš  Cannot access cluster API: $cluster"
              fi
            else
              echo "  âš  Netbird IP not configured for $cluster"
            fi

            echo ""
          done

          echo "Kubeconfig contexts configured:"
          kubectl config get-contexts
        env:
          SECRET_PREFIX: ""  # Will be set dynamically in loop

      # Get hub cluster context
      - name: Get Hub Cluster Info
        id: cluster_info
        run: |
          CONTEXT="gke_${{ secrets.GCP_PROJECT_ID }}_${{ secrets.HUB_CLUSTER_LOCATION }}_${{ secrets.HUB_CLUSTER_NAME }}"
          echo "context=$CONTEXT" >> $GITHUB_OUTPUT

      # Install Terraform CLI
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      # Remove stale backend configuration files
      - name: Cleanup old backend configs
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          rm -f backend.tf backend-config.tf

      # Generate backend-config.tf for remote state storage in GCS
      # State file location: gs://<bucket>/terraform/argocd-spokes/terraform.tfstate
      - name: Configure backend
        working-directory: ${{ env.WORKING_DIR }} 
        run: |
          bash ../../../../.github/scripts/configure-backend.sh "${{ env.CLOUD_PROVIDER }}" "argocd-spokes"
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}

      # Initialize Terraform
      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init

      # Import existing resources (optional)
      - name: Import Existing Resources
        if: ${{ inputs.adopt_existing_resources == true }}
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "Checking for existing ArgoCD agent resources to import..."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          # Read spoke cluster list
          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"
          if [ -z "$SPOKE_CLUSTERS" ]; then
            SPOKE_CLUSTERS="spoke-1,spoke-2,spoke-3"
          fi

          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"

          for cluster in "${CLUSTERS[@]}"; do
            cluster=$(echo "$cluster" | xargs)
            echo "Checking $cluster..."

            # Check if namespace exists
            if kubectl get namespace ${{ env.SPOKE_NAMESPACE }} --context $cluster 2>/dev/null; then
              echo "âœ“ Found existing argocd namespace on $cluster"
              # Note: Terraform module uses for_each, import syntax would be complex
              # null_resource imports not needed, they'll re-run idempotently
            else
              echo "â„¹ No existing argocd namespace on $cluster"
            fi
          done

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "Import check complete! Proceeding with Terraform operations..."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      # Validate Terraform syntax
      - name: Terraform Validate
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform validate

      # Generate terraform.tfvars with spoke deployment configuration
      - name: Create terraform.tfvars
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          # Build workload_clusters map from SPOKE_CLUSTERS  secret
          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"
          if [ -z "$SPOKE_CLUSTERS" ]; then
            SPOKE_CLUSTERS="spoke-1,spoke-2,spoke-3"
          fi

          # Convert comma-separated list to Terraform map format
          CLUSTERS_MAP="{"
          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"
          for i in "${!CLUSTERS[@]}"; do
            cluster=$(echo "${CLUSTERS[$i]}" | xargs)
            #  Derive agent namespace name from cluster name.
            # Example: spoke-2 -> agent-2, spoke2 -> agent-2
            agent="$cluster"
            agent=$(echo "$agent" | sed -E 's/^spoke-?/agent-/')
            agent=$(echo "$agent" | sed -E 's/agent-+$/agent/')
            if [ $i -gt 0 ]; then
              CLUSTERS_MAP="$CLUSTERS_MAP, "
            fi
            CLUSTERS_MAP="$CLUSTERS_MAP\"$agent\" = \"$cluster\""
          done
          CLUSTERS_MAP="$CLUSTERS_MAP}"

          cat > terraform.tfvars <<EOF
          # Deployment control
          deploy_hub                   = false
          deploy_spokes                = true

          # Cluster configuration
          hub_cluster_context          = "${{ steps.cluster_info.outputs.context }}"
          workload_clusters            = $CLUSTERS_MAP

          # ArgoCD configuration
          argocd_version               = "${{ env.ARGOCD_VERSION }}"
          hub_namespace                = "${{ env.HUB_NAMESPACE }}"
          spoke_namespace              = "${{ env.SPOKE_NAMESPACE }}"

          # Principal connection (from hub deployment)
          principal_address            = "${{ secrets.HUB_PRINCIPAL_ADDRESS }}"
          principal_port               = ${{ secrets.HUB_PRINCIPAL_PORT || 443 }}

          # Keycloak integration (optional)
          enable_keycloak              = ${{ vars.ENABLE_KEYCLOAK || 'false' }}
          keycloak_url                 = "${{ secrets.KEYCLOAK_URL }}"
          keycloak_user                = "${{ secrets.KEYCLOAK_USER }}"
          keycloak_password            = "${{ secrets.KEYCLOAK_PASSWORD }}"
          keycloak_realm               = "${{ vars.KEYCLOAK_REALM || 'argocd' }}"
          argocd_url                   = "${{ secrets.ARGOCD_URL }}"
          create_default_admin_user    = ${{ vars.CREATE_DEFAULT_ADMIN_USER || 'true' }}
          default_admin_username       = "${{ vars.DEFAULT_ADMIN_USERNAME || 'argocd-admin' }}"
          default_admin_email          = "${{ vars.DEFAULT_ADMIN_EMAIL || 'admin@argocd.local' }}"
          default_admin_password       = "${{ secrets.DEFAULT_ADMIN_PASSWORD }}"
          default_admin_password_temporary = ${{ vars.DEFAULT_ADMIN_PASSWORD_TEMPORARY || 'true' }}

          # AppProject configuration
          enable_appproject_sync       = true
          appproject_default_source_namespaces = ["*"]
          appproject_default_dest_server       = "*"
          appproject_default_dest_namespaces   = ["*"]
          EOF

          echo "Generated terraform.tfvars:"
          cat terraform.tfvars

      # Execute Terraform plan
      - name: Terraform Plan
        id: plan
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          set +e
          terraform plan -out=tfplan -detailed-exitcode
          EXIT_CODE=$?
          set -e

          echo "exitcode=$EXIT_CODE" >> $GITHUB_OUTPUT

          if [ $EXIT_CODE -eq 1 ]; then
            echo "âŒ Terraform plan failed!"
            exit 1
          fi

          terraform show tfplan > plan.txt
          exit 0

      # Save plan artifacts
      - name: Upload plan
        uses: actions/upload-artifact@v6
        with:
          name: tfplan-argocd-spokes-netbird
          path: |
            ${{ env.WORKING_DIR }}/tfplan
            ${{ env.WORKING_DIR }}/plan.txt
          retention-days: 5


  # Job 2: Apply Terraform plan and verify deployment
  terraform-apply-and-verify:
    name: Terraform Apply & Verify
    runs-on: ubuntu-latest
    needs: [terraform-plan]
    if: |
      (github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.terraform_action == 'apply')
    environment:
      name: production

    steps:
      # Fetch repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # CRITICAL: Connect runner to Netbird network
      # Netbird cloud version setup
      - name: Install Netbird CLI
        run: |
          curl -fsSL https://pkgs.netbird.io/install.sh | sh

      - name: Connect to Netbird
        run: |
          netbird up --setup-key ${{ secrets.NETBIRD_SETUP_KEY_RUNNERS }} 
      # Wait for Netbird peer sync
      - name: Wait for Netbird peer sync
        run: |
          echo "â³ Waiting for Netbird peer sync..."
          MAX_WAIT=60
          WAITED=0
          
          while [ $WAITED -lt $MAX_WAIT ]; do
            PEERS=$(netbird status | grep "Peers count" | awk '{print $3}')
            echo "Current peers: $PEERS (waited ${WAITED}s)"
            
            # Check if we have connected peers (format: X/Y Connected)
            if echo "$PEERS" | grep -q "/.*Connected" && ! echo "$PEERS" | grep -q "0/0"; then
              echo "âœ… Peers synced!"
              netbird status
              exit 0
            fi
            
            sleep 5
            WAITED=$((WAITED + 5))
          done
          
          echo "âš  Peer sync timeout after ${MAX_WAIT}s, proceeding anyway..."
          netbird status

      # Install Terraform CLI
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      # Authenticate to GCP
      - name: Setup GCP credentials
        uses: google-github-actions/auth@v3
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Install gcloud CLI
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v3

      # Install kubectl
      - name: Setup kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Install GKE auth plugin
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
          curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk-gke-gcloud-auth-plugin

      # Install argocd-agentctl for certificate generation
      - name: Install argocd-agentctl
        run: |
          curl -L -f https://github.com/argoproj-labs/argocd-agent/releases/download/v0.5.3/argocd-agentctl_linux-amd64 -o /tmp/argocd-agentctl
          file /tmp/argocd-agentctl
          chmod +x /tmp/argocd-agentctl
          sudo mv /tmp/argocd-agentctl /usr/local/bin/argocd-agentctl
          /usr/local/bin/argocd-agentctl version

          # Configure hub cluster
          gcloud container clusters get-credentials ${{ secrets.HUB_CLUSTER_NAME }} \
            --region=${{ secrets.HUB_CLUSTER_LOCATION }} \
            --project=${{ secrets.GCP_PROJECT_ID }}

      # Generate kubeconfig for spoke clusters (same as plan job)
      - name: Generate kubeconfig for spoke clusters
        run: |
          echo "ğŸ”§ Generating kubeconfig for local spoke clusters..."

          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"
          if [ -z "$SPOKE_CLUSTERS" ]; then
            SPOKE_CLUSTERS="spoke-1,spoke-2,spoke-3"
          fi

          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"

          for cluster in "${CLUSTERS[@]}"; do
            cluster=$(echo "$cluster" | xargs)

            # Get Netbird IP and certificates based on cluster name
            case "$cluster" in
              spoke-1|spoke-2)
                NETBIRD_IP="${{ secrets.SPOKE_1_NETBIRD_IP }}"
                # Strip /32 suffix if present (CIDR notation)
                NETBIRD_IP="${NETBIRD_IP%/32}"
                CA_CERT="${{ secrets.SPOKE_1_CA_CERT }}"
                CLIENT_CERT="${{ secrets.SPOKE_1_CLIENT_CERT }}"
                CLIENT_KEY="${{ secrets.SPOKE_1_CLIENT_KEY }}"
                ;;
              *)
                echo "  âš  Unknown cluster: $cluster"
                echo "  Expected cluster name: spoke-1 or spoke-2"
                echo "  Please check your SPOKE_CLUSTERS secret"
                continue
                ;;
            esac

            echo "Configuring $cluster..."

            if [ ! -z "$NETBIRD_IP" ]; then
              echo "  Netbird IP: $NETBIRD_IP"

              kubectl config set-cluster $cluster \
                --server=https://$NETBIRD_IP:6443 \
                --certificate-authority=<(echo "$CA_CERT" | base64 -d) \
                --embed-certs=true

              kubectl config set-credentials $cluster-admin \
                --client-certificate=<(echo "$CLIENT_CERT" | base64 -d) \
                --client-key=<(echo "$CLIENT_KEY" | base64 -d) \
                --embed-certs=true

              kubectl config set-context $cluster \
                --cluster=$cluster \
                --user=$cluster-admin
            fi
          done

          kubectl config get-contexts

      # Get hub context
      - name: Get Hub Cluster Info
        id: cluster_info
        run: |
          CONTEXT="gke_${{ secrets.GCP_PROJECT_ID }}_${{ secrets.HUB_CLUSTER_LOCATION }}_${{ secrets.HUB_CLUSTER_NAME }}"
          echo "context=$CONTEXT" >> $GITHUB_OUTPUT

      # Recreate terraform.tfvars (must match plan job)
      - name: Create terraform.tfvars
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"
          if [ -z "$SPOKE_CLUSTERS" ]; then
            SPOKE_CLUSTERS="spoke-1"
          fi

          CLUSTERS_MAP="{"
          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"
          for i in "${!CLUSTERS[@]}"; do
            cluster=$(echo "${CLUSTERS[$i]}" | xargs)
            if [ $i -gt 0 ]; then
              CLUSTERS_MAP="$CLUSTERS_MAP, "
            fi
            CLUSTERS_MAP="$CLUSTERS_MAP\"$cluster\" = \"$cluster\""
          done
          CLUSTERS_MAP="$CLUSTERS_MAP}"

          cat > terraform.tfvars <<EOF
          deploy_hub                   = false
          deploy_spokes                = true
          hub_cluster_context          = "${{ steps.cluster_info.outputs.context }}"
          workload_clusters            = $CLUSTERS_MAP
          argocd_version               = "${{ env.ARGOCD_VERSION }}"
          hub_namespace                = "${{ env.HUB_NAMESPACE }}"
          spoke_namespace              = "${{ env.SPOKE_NAMESPACE }}"
          principal_address            = "${{ secrets.HUB_PRINCIPAL_ADDRESS }}"
          principal_port               = ${{ secrets.HUB_PRINCIPAL_PORT || 443 }}

          # Keycloak integration (optional)
          enable_keycloak              = ${{ vars.ENABLE_KEYCLOAK || 'false' }}
          keycloak_url                 = "${{ secrets.KEYCLOAK_URL }}"
          keycloak_user                = "${{ secrets.KEYCLOAK_USER }}"
          keycloak_password            = "${{ secrets.KEYCLOAK_PASSWORD }}"
          keycloak_realm               = "${{ vars.KEYCLOAK_REALM || 'argocd' }}"
          argocd_url                   = "${{ secrets.ARGOCD_URL }}"
          create_default_admin_user    = ${{ vars.CREATE_DEFAULT_ADMIN_USER || 'true' }}
          default_admin_username       = "${{ vars.DEFAULT_ADMIN_USERNAME || 'argocd-admin' }}"
          default_admin_email          = "${{ vars.DEFAULT_ADMIN_EMAIL || 'admin@argocd.local' }}"
          default_admin_password       = "${{ secrets.DEFAULT_ADMIN_PASSWORD }}"
          default_admin_password_temporary = ${{ vars.DEFAULT_ADMIN_PASSWORD_TEMPORARY || 'true' }}

          enable_appproject_sync       = true
          appproject_default_source_namespaces = ["*"]
          appproject_default_dest_server       = "*"
          appproject_default_dest_namespaces   = ["*"]
          EOF

      # Remove stale backend configs
      - name: Cleanup old backend configs
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          rm -f backend.tf backend-config.tf

      # Regenerate backend configuration
      - name: Configure backend
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          bash ../../../../.github/scripts/configure-backend.sh "${{ env.CLOUD_PROVIDER }}" "argocd-spokes"
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}

      # Re-initialize Terraform
      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init

      # Download the plan artifact
      - name: Download plan
        uses: actions/download-artifact@v7
        with:
          name: tfplan-argocd-spokes-netbird
          path: ${{ env.WORKING_DIR }}

      # Execute the plan to deploy spoke clusters
      - name: Terraform Apply
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform apply -auto-approve tfplan

      # Extract Terraform outputs
      - name: Output deployment info
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform output -json > terraform-outputs.json

      # Save outputs as artifact
      - name: Upload outputs
        uses: actions/upload-artifact@v6
        with:
          name: terraform-outputs-argocd-spokes-netbird
          path: ${{ env.WORKING_DIR }}/terraform-outputs.json
          retention-days: 30

      # Verify successful deployment
      - name: Verify ArgoCD Spoke deployment
        run: |
          echo "ğŸ” Verifying ArgoCD Agent spoke deployment..."

          SPOKE_CLUSTERS="${{ secrets.SPOKE_CLUSTERS }}"
          if [ -z "$SPOKE_CLUSTERS" ]; then
            SPOKE_CLUSTERS="spoke-1,spoke-2,spoke-3"
          fi

          IFS=',' read -ra CLUSTERS <<< "$SPOKE_CLUSTERS"

          SUCCESS_COUNT=0
          FAIL_COUNT=0

          for cluster in "${CLUSTERS[@]}"; do
            cluster=$(echo "$cluster" | xargs)
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "Verifying $cluster..."
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            # Test 1: Namespace exists
            echo "1. Checking namespace..."
            if kubectl get namespace ${{ env.SPOKE_NAMESPACE }} --context $cluster 2>/dev/null; then
              echo "   âœ… Namespace exists"
            else
              echo "   âŒ Namespace not found"
              FAIL_COUNT=$((FAIL_COUNT + 1))
              continue
            fi

            # Test 2: ArgoCD components ready
            echo "2. Checking ArgoCD pods..."
            if kubectl get pods -n ${{ env.SPOKE_NAMESPACE }} --context $cluster 2>/dev/null; then
              kubectl wait --for=condition=ready pod \
                -l app.kubernetes.io/part-of=argocd \
                -n ${{ env.SPOKE_NAMESPACE }} \
                --context $cluster \
                --timeout=300s && echo "   âœ… All pods ready" || echo "   âš  Some pods not ready"
            else
              echo "   âŒ Cannot get pods"
              FAIL_COUNT=$((FAIL_COUNT + 1))
              continue
            fi

            # Test 3: Agent connected to principal
            echo "3. Checking agent connection..."
            sleep 10  # Allow time for agent connection

            AGENT_LOGS=$(kubectl logs -l app.kubernetes.io/name=argocd-agent-agent \
              -n ${{ env.SPOKE_NAMESPACE }} \
              --context $cluster \
              --tail=100 2>/dev/null || echo "")

            if echo "$AGENT_LOGS" | grep -qi "connected to principal\|authentication successful\|registered with principal"; then
              echo "   âœ… Agent connected to principal"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
            else
              echo "   âŒ Agent connection not confirmed"
              echo "   Recent logs:"
              echo "$AGENT_LOGS" | tail -20
              FAIL_COUNT=$((FAIL_COUNT + 1))
            fi

            # Test 4: Agent certificates exist
            echo "4. Checking certificates..."
            if kubectl get secret argocd-agent-client-tls -n ${{ env.SPOKE_NAMESPACE }} --context $cluster 2>/dev/null; then
              echo "   âœ… Client certificate exists"
            else
              echo "   âš  Client certificate not found"
            fi

            if kubectl get secret argocd-agent-ca -n ${{ env.SPOKE_NAMESPACE }} --context $cluster 2>/dev/null; then
              echo "   âœ… CA certificate exists"
            else
              echo "   âš  CA certificate not found"
            fi
          done

          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ğŸ“Š Verification Summary"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "âœ… Successfully connected: $SUCCESS_COUNT"
          echo "âŒ Failed connections: $FAIL_COUNT"
          echo ""

          if [ $FAIL_COUNT -gt 0 ]; then
            echo "âš  Some spoke clusters had connection issues"
            echo "   Check agent logs for troubleshooting"
            exit 1
          else
            echo "âœ… All spoke clusters deployed and connected successfully!"
          fi

          echo ""
          echo "ğŸ“ Next Steps:"
          echo "   1. Access ArgoCD UI at: ${{ secrets.ARGOCD_URL }}"
          echo "   2. Verify spoke clusters appear in Settings â†’ Clusters"
          echo "   3. Deploy test application to validate agent functionality"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
